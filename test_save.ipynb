{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer\n",
    "import silence_tensorflow.auto\n",
    "import numpy as np\n",
    "\n",
    "N_TIMESTEPS = 5\n",
    "MAX_N_HARPS = 5\n",
    "N_FEATURES = 21\n",
    "INPUT_DIM = (N_TIMESTEPS, MAX_N_HARPS, N_FEATURES)\n",
    "N_OUT = 2\n",
    "OUTPUT_DIM =(N_TIMESTEPS,N_OUT)\n",
    "NUM_LAYERS = 3\n",
    "D_MODEL = 12\n",
    "DFF = 24\n",
    "NUM_HEADS = 3\n",
    "RATE = 0.1\n",
    "\n",
    "assert N_FEATURES > D_MODEL\n",
    "assert D_MODEL % NUM_HEADS == 0\n",
    "\n",
    "t = Transformer(\n",
    "    num_layers=NUM_LAYERS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dff=DFF,\n",
    "    input_dimensions=INPUT_DIM,\n",
    "    target_dimensions=OUTPUT_DIM,\n",
    "    rate=RATE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([np.random.random(INPUT_DIM) for _ in range(10)])\n",
    "y = np.array([np.random.random(OUTPUT_DIM) for _ in range(10)])\n",
    "\n",
    "y_pred, _ = t((X, y), training=True)\n",
    "np.any(np.isnan(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 575.72it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 546.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "metadata = {}\n",
    "sharp_df = pd.read_csv('data/sharp.csv')\n",
    "sharp_columns = [\n",
    "    \"timestamp\",\n",
    "    \"harp\",\n",
    "    \"USFLUX\",\n",
    "    \"MEANGAM\",\n",
    "    \"MEANGBT\",\n",
    "    \"MEANGBZ\",\n",
    "    \"MEANGBH\",\n",
    "    \"TOTPOT\",\n",
    "    \"TOTUSJZ\",\n",
    "    \"TOTUSJH\",\n",
    "    \"ABSNJZH\",\n",
    "    \"SAVNCPP\",\n",
    "    \"MEANPOT\",\n",
    "    \"MEANSHR\",\n",
    "    \"SHRGT45\",\n",
    "    \"SIZE\",\n",
    "    \"SIZE_ACR\",\n",
    "    \"NACR\",\n",
    "    \"NPIX\",\n",
    "    \"MEANJZD\",\n",
    "    \"MEANALP\",\n",
    "    \"MEANJZH\",\n",
    "]\n",
    "\n",
    "sharp_df = sharp_df[sharp_columns]\n",
    "sharp_df = sharp_df.dropna()\n",
    "sharp_df_notime = sharp_df[sharp_columns[1:]]\n",
    "\n",
    "metadata[\"sharp_mean\"] = sharp_df_notime.mean().to_numpy()\n",
    "metadata[\"sharp_std\"] = sharp_df_notime.std().to_numpy()\n",
    "sharp_df_notime -= sharp_df_notime.mean()\n",
    "sharp_df_notime /= sharp_df_notime.std()\n",
    "sharp_df_notime[\"timestamp\"] = sharp_df[\"timestamp\"]\n",
    "sharp_df = sharp_df_notime\n",
    "\n",
    "\n",
    "xray_df = pd.read_csv('data/xray.csv')\n",
    "xray_columns = [\"timestamp\", \"Short\", \"Long\"]\n",
    "xray_df = xray_df[xray_columns]\n",
    "xray_df = xray_df[(xray_df[\"Short\"] > 0.0) & (xray_df[\"Long\"] > 0.0)]\n",
    "xray_df_notime = xray_df[xray_columns[1:]]\n",
    "xray_df_notime = xray_df_notime.dropna()\n",
    "\n",
    "metadata[\"xray_mean\"] = xray_df_notime.mean().to_numpy()\n",
    "metadata[\"xray_std\"] = xray_df_notime.std().to_numpy()\n",
    "xray_df_notime -= xray_df_notime.mean()\n",
    "xray_df_notime += xray_df_notime.std()\n",
    "xray_df_notime[\"timestamp\"] = xray_df[\"timestamp\"]\n",
    "xray_df = xray_df_notime\n",
    "\n",
    "data = sharp_df.merge(xray_df, on='timestamp')\n",
    "\n",
    "train_data = []\n",
    "\n",
    "\n",
    "def create_train_data_tuple():\n",
    "    random_time = datetime.fromtimestamp(int(data.sample(1)[\"timestamp\"]))\n",
    "    start, end = (random_time -\n",
    "                  timedelta(hours=1)).timestamp(), random_time.timestamp()\n",
    "    tmp_data = data[(data[\"timestamp\"] > start) & (data[\"timestamp\"] <= end)]\n",
    "    harps = tmp_data[\"harp\"].unique()\n",
    "\n",
    "    input_ = np.zeros(INPUT_DIM)\n",
    "    output = np.zeros(OUTPUT_DIM)\n",
    "\n",
    "    for i, harp in enumerate(harps):\n",
    "        if i == 5:\n",
    "            break\n",
    "        harp_data = tmp_data[tmp_data[\"harp\"] == harp]\n",
    "        input_data = harp_data[sharp_columns[1:]].to_numpy()\n",
    "        n_timesteps = input_data.shape[0]\n",
    "        if i == 0:\n",
    "            output_data = harp_data[[\"Short\", \"Long\"]].to_numpy()\n",
    "            output[:n_timesteps, :] = output_data\n",
    "\n",
    "        input_[:n_timesteps, i, :] = input_data\n",
    "\n",
    "    return input_, output\n",
    "\n",
    "\n",
    "def get_data(size=1000):\n",
    "    X, y = [], []\n",
    "    for _ in tqdm(range(size)):\n",
    "        X_, y_ = create_train_data_tuple()\n",
    "        X.append(X_)\n",
    "        y.append(y_)\n",
    "    return X, y\n",
    "\n",
    "X, y = get_data(1000)\n",
    "X_val, y_val = get_data(100)\n",
    "\n",
    "print(np.any(np.isnan(X)))\n",
    "print(np.any(np.isnan(y)))\n",
    "print(np.any(np.isnan(X_val)))\n",
    "print(np.any(np.isnan(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0: mean_loss = 0.05319864000281086\n",
      "EPOCH 0: val_loss = 0.016247836872935295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1: mean_loss = 0.0008050289155653445\n",
      "EPOCH 1: val_loss = 0.009096811525523663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2: mean_loss = 0.0005437742564026848\n",
      "EPOCH 2: val_loss = 0.006016748026013374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3: mean_loss = 0.0005651527261034062\n",
      "EPOCH 3: val_loss = 0.0025222860276699066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4: mean_loss = 0.0003520178583858069\n",
      "EPOCH 4: val_loss = 0.0035190414637327194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5: mean_loss = 0.00015316514294681836\n",
      "EPOCH 5: val_loss = 0.0024403678253293037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6: mean_loss = 0.00018476169545465383\n",
      "EPOCH 6: val_loss = 0.0022367103956639767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 7: mean_loss = 0.00021666039833689865\n",
      "EPOCH 7: val_loss = 0.001420822343789041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 8: mean_loss = 8.403554178585182e-05\n",
      "EPOCH 8: val_loss = 0.0015561613254249096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 9: mean_loss = 2.5262686369842414e-05\n",
      "EPOCH 9: val_loss = 0.0010481922654435039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    N = len(X) // BATCH_SIZE\n",
    "    for batch in tqdm(range(N)):\n",
    "        X_batch, y_batch = X[epoch*BATCH_SIZE:(epoch+1)*BATCH_SIZE], y[epoch*BATCH_SIZE:(epoch+1)*BATCH_SIZE]\n",
    "        X_batch, y_batch = np.array(X_batch), np.array(y_batch)\n",
    "        \n",
    "        assert not np.any(np.isnan(X_batch)), \"X_batch should not include nan\"\n",
    "        assert not np.any(np.isnan(y_batch)), \"y_batch should not include nan\"\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred, _ = t((X_batch, y_batch), training=False)\n",
    "        \n",
    "            assert not np.any(np.isnan(y_pred)), \"y_pred should not include nan\"\n",
    "        \n",
    "            loss_value = loss(y_batch, y_pred)\n",
    "        \n",
    "        gradients = tape.gradient(loss_value, t.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, t.trainable_variables))\n",
    "        \n",
    "        total_loss += loss_value.numpy()\n",
    "\n",
    "    print(f\"EPOCH {epoch}: mean_loss = {total_loss / N}\")\n",
    "    \n",
    "    y_pred_val, _ = t((np.array(X_val), np.array(y_val)))\n",
    "    val_loss = loss(y_val, y_pred_val).numpy()\n",
    "    \n",
    "    print(f\"EPOCH {epoch}: val_loss = {val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "MODELNAME = \"8h-1\"\n",
    "\n",
    "metadata[\"n_timesteps\"]  = N_TIMESTEPS\n",
    "metadata[\"max_n_harps\"]  = MAX_N_HARPS\n",
    "metadata[\"n_features\"] = N_FEATURES\n",
    "metadata[\"n_out\"]  = N_OUT\n",
    "metadata[\"num_layers\"] = NUM_LAYERS\n",
    "metadata[\"d_model\"] = D_MODEL\n",
    "metadata[\"num_heads\"] = NUM_HEADS\n",
    "metadata[\"dff\"] = DFF\n",
    "metadata[\"input_dim\"] = INPUT_DIM\n",
    "metadata[\"output_dim\"] = OUTPUT_DIM\n",
    "metadata[\"rate\"] = RATE\n",
    "\n",
    "\n",
    "\n",
    "t.save_weights(\"models/\"+MODELNAME)\n",
    "with open(\"meta/\"+MODELNAME+\".pkl\", \"wb\") as metafile:\n",
    "    metafile.write(pickle.dumps(metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras import models\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformer import Transformer\n",
    "\n",
    "\n",
    "class Avocato():\n",
    "    def __init__(self, modelname):\n",
    "        self.metadata = pickle.load(\n",
    "            open(\"/mnt/hackathon2021/modelcache/meta/\" + modelname + \".pkl\",\n",
    "                 \"rb\"))\n",
    "        self.model = Transformer(\n",
    "            num_layers=self.metadata[\"num_layers\"],\n",
    "            d_model=self.metadata[\"d_model\"],\n",
    "            num_heads=self.metadata[\"num_heads\"],\n",
    "            dff=self.metadata[\"dff\"],\n",
    "            input_dimensions=self.metadata[\"input_dim\"],\n",
    "            target_dimensions=self.metadata[\"output_dim\"],\n",
    "            rate=self.metadata[\"rate\"],\n",
    "        )\n",
    "        self.model.compile()\n",
    "        self.model.load_weights(\"/mnt/hackathon2021/modelcache/models/\" +\n",
    "                                modelname)\n",
    "\n",
    "    def __call__(self, net_in):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        -----\n",
    "            - net_in: pd dataframe consisting of n_timesteps of data for HARPS (timestamp, harp, ...parameters)\n",
    "        \"\"\"\n",
    "\n",
    "        in_data = np.zeros(\n",
    "            (1, self.metadata[\"n_timesteps\"], self.metadata[\"max_n_harps\"],\n",
    "             self.metadata[\"n_features\"]))\n",
    "        unique_timesteps = net_in[\"timestamp\"].unique()\n",
    "        for t_id, timestep in enumerate(unique_timesteps):\n",
    "            if t_id >= self.metadata[\"n_timesteps\"]:\n",
    "                continue\n",
    "            unique_harps = net_in[net_in[\"timestamp\"] ==\n",
    "                                  timestep][\"harp\"].unique()\n",
    "            for h_id, harp in enumerate(unique_harps):\n",
    "                if h_id >= self.metadata[\"max_n_harps\"]:\n",
    "                    continue\n",
    "                in_data[0, t_id, h_id] = net_in[\n",
    "                    (net_in[\"timestamp\"] == timestep) &\n",
    "                    (net_in[\"harp\"] == harp\n",
    "                     )].loc[:,\n",
    "                            net_in.columns != \"timestamp\"].to_numpy().reshape(\n",
    "                                self.metadata[\"n_features\"])\n",
    "                in_data[0, t_id, h_id] -= self.metadata[\"sharp_mean\"]\n",
    "                in_data[0, t_id, h_id] /= self.metadata[\"sharp_std\"]\n",
    "\n",
    "        output = np.zeros((\n",
    "            1,\n",
    "            self.metadata[\"n_timesteps\"],\n",
    "            self.metadata[\"n_out\"],\n",
    "        ))\n",
    "\n",
    "        for i in tf.range(self.metadata[\"n_timesteps\"]):\n",
    "            output, _ = self.model([in_data, output],\n",
    "                                              training=False)\n",
    "\n",
    "        return output * self.metadata[\"xray_std\"] + self.metadata[\"xray_mean\"], output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = \"8h-1\"\n",
    "pred = Avocato(MODELNAME)\n",
    "random_time = datetime.fromtimestamp(int(data.sample(1)[\"timestamp\"]))\n",
    "start, end = (random_time -\n",
    "                timedelta(hours=1)).timestamp(), random_time.timestamp()\n",
    "net_in = data[(data[\"timestamp\"] > start) & (data[\"timestamp\"] <= end)]\n",
    "net_in = net_in[sharp_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 5, 2), dtype=float32, numpy=\n",
       " array([[[2.9338644e-08, 8.2975248e-08],\n",
       "         [2.9338644e-08, 8.2975248e-08],\n",
       "         [2.9338640e-08, 8.2975255e-08],\n",
       "         [2.9338642e-08, 8.2975248e-08],\n",
       "         [2.9338645e-08, 8.2975248e-08]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5, 2), dtype=float32, numpy=\n",
       " array([[[0.39534798, 0.02663079],\n",
       "         [0.39534798, 0.02663079],\n",
       "         [0.3953478 , 0.02663084],\n",
       "         [0.39534786, 0.02663079],\n",
       "         [0.3953481 , 0.02663079]]], dtype=float32)>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(net_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>harp</th>\n",
       "      <th>USFLUX</th>\n",
       "      <th>MEANGAM</th>\n",
       "      <th>MEANGBT</th>\n",
       "      <th>MEANGBZ</th>\n",
       "      <th>MEANGBH</th>\n",
       "      <th>TOTPOT</th>\n",
       "      <th>TOTUSJZ</th>\n",
       "      <th>TOTUSJH</th>\n",
       "      <th>...</th>\n",
       "      <th>MEANPOT</th>\n",
       "      <th>MEANSHR</th>\n",
       "      <th>SHRGT45</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>SIZE_ACR</th>\n",
       "      <th>NACR</th>\n",
       "      <th>NPIX</th>\n",
       "      <th>MEANJZD</th>\n",
       "      <th>MEANALP</th>\n",
       "      <th>MEANJZH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>1.555192e+09</td>\n",
       "      <td>-0.54972</td>\n",
       "      <td>1.463450</td>\n",
       "      <td>1.908409</td>\n",
       "      <td>-1.013866</td>\n",
       "      <td>-1.030139</td>\n",
       "      <td>-0.017631</td>\n",
       "      <td>3.013533</td>\n",
       "      <td>1.769887</td>\n",
       "      <td>1.400974</td>\n",
       "      <td>...</td>\n",
       "      <td>3.216637</td>\n",
       "      <td>2.081325</td>\n",
       "      <td>2.171866</td>\n",
       "      <td>4.147030</td>\n",
       "      <td>3.967177</td>\n",
       "      <td>3.964512</td>\n",
       "      <td>4.153964</td>\n",
       "      <td>-0.430136</td>\n",
       "      <td>-0.207704</td>\n",
       "      <td>-0.514086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6205</th>\n",
       "      <td>1.555193e+09</td>\n",
       "      <td>-0.54972</td>\n",
       "      <td>1.467110</td>\n",
       "      <td>1.903470</td>\n",
       "      <td>-0.992921</td>\n",
       "      <td>-1.005052</td>\n",
       "      <td>-0.006907</td>\n",
       "      <td>3.015453</td>\n",
       "      <td>1.802248</td>\n",
       "      <td>1.431595</td>\n",
       "      <td>...</td>\n",
       "      <td>3.228418</td>\n",
       "      <td>2.074768</td>\n",
       "      <td>2.168833</td>\n",
       "      <td>4.146119</td>\n",
       "      <td>3.973329</td>\n",
       "      <td>3.970555</td>\n",
       "      <td>4.152936</td>\n",
       "      <td>-0.513553</td>\n",
       "      <td>-0.214100</td>\n",
       "      <td>-0.535922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6206</th>\n",
       "      <td>1.555194e+09</td>\n",
       "      <td>-0.54972</td>\n",
       "      <td>1.475988</td>\n",
       "      <td>1.884381</td>\n",
       "      <td>-0.990427</td>\n",
       "      <td>-1.011456</td>\n",
       "      <td>-0.006732</td>\n",
       "      <td>3.008407</td>\n",
       "      <td>1.827295</td>\n",
       "      <td>1.434200</td>\n",
       "      <td>...</td>\n",
       "      <td>3.211264</td>\n",
       "      <td>2.069357</td>\n",
       "      <td>2.160744</td>\n",
       "      <td>4.142865</td>\n",
       "      <td>3.935855</td>\n",
       "      <td>3.932949</td>\n",
       "      <td>4.149537</td>\n",
       "      <td>-0.522516</td>\n",
       "      <td>-0.228642</td>\n",
       "      <td>-0.581886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6207</th>\n",
       "      <td>1.555194e+09</td>\n",
       "      <td>-0.54972</td>\n",
       "      <td>1.463759</td>\n",
       "      <td>1.876689</td>\n",
       "      <td>-0.972287</td>\n",
       "      <td>-0.984784</td>\n",
       "      <td>0.015472</td>\n",
       "      <td>2.994272</td>\n",
       "      <td>1.762063</td>\n",
       "      <td>1.420395</td>\n",
       "      <td>...</td>\n",
       "      <td>3.270639</td>\n",
       "      <td>2.046461</td>\n",
       "      <td>2.153386</td>\n",
       "      <td>4.137834</td>\n",
       "      <td>3.908661</td>\n",
       "      <td>3.905640</td>\n",
       "      <td>4.144374</td>\n",
       "      <td>-0.485809</td>\n",
       "      <td>-0.238160</td>\n",
       "      <td>-0.619144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6208</th>\n",
       "      <td>1.555195e+09</td>\n",
       "      <td>-0.54972</td>\n",
       "      <td>1.476268</td>\n",
       "      <td>1.870611</td>\n",
       "      <td>-0.975529</td>\n",
       "      <td>-0.994324</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>3.005051</td>\n",
       "      <td>1.771407</td>\n",
       "      <td>1.451214</td>\n",
       "      <td>...</td>\n",
       "      <td>3.217841</td>\n",
       "      <td>2.045837</td>\n",
       "      <td>2.134906</td>\n",
       "      <td>4.132754</td>\n",
       "      <td>3.858636</td>\n",
       "      <td>3.855499</td>\n",
       "      <td>4.139157</td>\n",
       "      <td>-0.461205</td>\n",
       "      <td>-0.251950</td>\n",
       "      <td>-0.657207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp     harp    USFLUX   MEANGAM   MEANGBT   MEANGBZ   MEANGBH  \\\n",
       "6204  1.555192e+09 -0.54972  1.463450  1.908409 -1.013866 -1.030139 -0.017631   \n",
       "6205  1.555193e+09 -0.54972  1.467110  1.903470 -0.992921 -1.005052 -0.006907   \n",
       "6206  1.555194e+09 -0.54972  1.475988  1.884381 -0.990427 -1.011456 -0.006732   \n",
       "6207  1.555194e+09 -0.54972  1.463759  1.876689 -0.972287 -0.984784  0.015472   \n",
       "6208  1.555195e+09 -0.54972  1.476268  1.870611 -0.975529 -0.994324  0.016288   \n",
       "\n",
       "        TOTPOT   TOTUSJZ   TOTUSJH  ...   MEANPOT   MEANSHR   SHRGT45  \\\n",
       "6204  3.013533  1.769887  1.400974  ...  3.216637  2.081325  2.171866   \n",
       "6205  3.015453  1.802248  1.431595  ...  3.228418  2.074768  2.168833   \n",
       "6206  3.008407  1.827295  1.434200  ...  3.211264  2.069357  2.160744   \n",
       "6207  2.994272  1.762063  1.420395  ...  3.270639  2.046461  2.153386   \n",
       "6208  3.005051  1.771407  1.451214  ...  3.217841  2.045837  2.134906   \n",
       "\n",
       "          SIZE  SIZE_ACR      NACR      NPIX   MEANJZD   MEANALP   MEANJZH  \n",
       "6204  4.147030  3.967177  3.964512  4.153964 -0.430136 -0.207704 -0.514086  \n",
       "6205  4.146119  3.973329  3.970555  4.152936 -0.513553 -0.214100 -0.535922  \n",
       "6206  4.142865  3.935855  3.932949  4.149537 -0.522516 -0.228642 -0.581886  \n",
       "6207  4.137834  3.908661  3.905640  4.144374 -0.485809 -0.238160 -0.619144  \n",
       "6208  4.132754  3.858636  3.855499  4.139157 -0.461205 -0.251950 -0.657207  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(TIMESTAMPS, ACTIVE_REGIONs, PARAMETERS)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "abbc665463d35b62cca70309c790e7d0ad7bb1e4d5ea5962f40350218dd6908d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
