{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer\n",
    "import silence_tensorflow.auto\n",
    "import numpy as np\n",
    "\n",
    "N_TIMESTEPS = 5\n",
    "MAX_N_HARPS = 5\n",
    "N_FEATURES = 21\n",
    "INPUT_DIM = (N_TIMESTEPS, MAX_N_HARPS, N_FEATURES)\n",
    "N_OUT = 2\n",
    "OUTPUT_DIM =(N_TIMESTEPS,N_OUT)\n",
    "NUM_LAYERS = 3\n",
    "D_MODEL = 12\n",
    "DFF = 24\n",
    "NUM_HEADS = 3\n",
    "RATE = 0.1\n",
    "\n",
    "assert N_FEATURES > D_MODEL\n",
    "assert D_MODEL % NUM_HEADS == 0\n",
    "\n",
    "t = Transformer(\n",
    "    num_layers=NUM_LAYERS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dff=DFF,\n",
    "    input_dimensions=INPUT_DIM,\n",
    "    target_dimensions=OUTPUT_DIM,\n",
    "    rate=RATE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([np.random.random(INPUT_DIM) for _ in range(10)])\n",
    "y = np.array([np.random.random(OUTPUT_DIM) for _ in range(10)])\n",
    "\n",
    "y_pred, _ = t((X, y), training=True)\n",
    "np.any(np.isnan(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 575.72it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 546.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "metadata = {}\n",
    "sharp_df = pd.read_csv('data/sharp.csv')\n",
    "sharp_columns = [\n",
    "    \"timestamp\",\n",
    "    \"harp\",\n",
    "    \"USFLUX\",\n",
    "    \"MEANGAM\",\n",
    "    \"MEANGBT\",\n",
    "    \"MEANGBZ\",\n",
    "    \"MEANGBH\",\n",
    "    \"TOTPOT\",\n",
    "    \"TOTUSJZ\",\n",
    "    \"TOTUSJH\",\n",
    "    \"ABSNJZH\",\n",
    "    \"SAVNCPP\",\n",
    "    \"MEANPOT\",\n",
    "    \"MEANSHR\",\n",
    "    \"SHRGT45\",\n",
    "    \"SIZE\",\n",
    "    \"SIZE_ACR\",\n",
    "    \"NACR\",\n",
    "    \"NPIX\",\n",
    "    \"MEANJZD\",\n",
    "    \"MEANALP\",\n",
    "    \"MEANJZH\",\n",
    "]\n",
    "\n",
    "sharp_df = sharp_df[sharp_columns]\n",
    "sharp_df = sharp_df.dropna()\n",
    "sharp_df_notime = sharp_df[sharp_columns[1:]]\n",
    "\n",
    "metadata[\"sharp_mean\"] = sharp_df_notime.mean().to_numpy()\n",
    "metadata[\"sharp_std\"] = sharp_df_notime.std().to_numpy()\n",
    "sharp_df_notime -= sharp_df_notime.mean()\n",
    "sharp_df_notime /= sharp_df_notime.std()\n",
    "sharp_df_notime[\"timestamp\"] = sharp_df[\"timestamp\"]\n",
    "sharp_df = sharp_df_notime\n",
    "\n",
    "\n",
    "xray_df = pd.read_csv('data/xray.csv')\n",
    "xray_columns = [\"timestamp\", \"Short\", \"Long\"]\n",
    "xray_df = xray_df[xray_columns]\n",
    "xray_df = xray_df[(xray_df[\"Short\"] > 0.0) & (xray_df[\"Long\"] > 0.0)]\n",
    "xray_df_notime = xray_df[xray_columns[1:]]\n",
    "xray_df_notime = xray_df_notime.dropna()\n",
    "\n",
    "metadata[\"xray_mean\"] = xray_df_notime.mean().to_numpy()\n",
    "metadata[\"xray_std\"] = xray_df_notime.std().to_numpy()\n",
    "xray_df_notime -= xray_df_notime.mean()\n",
    "xray_df_notime += xray_df_notime.std()\n",
    "xray_df_notime[\"timestamp\"] = xray_df[\"timestamp\"]\n",
    "xray_df = xray_df_notime\n",
    "\n",
    "data = sharp_df.merge(xray_df, on='timestamp')\n",
    "\n",
    "train_data = []\n",
    "\n",
    "\n",
    "def create_train_data_tuple():\n",
    "    random_time = datetime.fromtimestamp(int(data.sample(1)[\"timestamp\"]))\n",
    "    start, end = (random_time -\n",
    "                  timedelta(hours=1)).timestamp(), random_time.timestamp()\n",
    "    tmp_data = data[(data[\"timestamp\"] > start) & (data[\"timestamp\"] <= end)]\n",
    "    harps = tmp_data[\"harp\"].unique()\n",
    "\n",
    "    input_ = np.zeros(INPUT_DIM)\n",
    "    output = np.zeros(OUTPUT_DIM)\n",
    "\n",
    "    for i, harp in enumerate(harps):\n",
    "        if i == 5:\n",
    "            break\n",
    "        harp_data = tmp_data[tmp_data[\"harp\"] == harp]\n",
    "        input_data = harp_data[sharp_columns[1:]].to_numpy()\n",
    "        n_timesteps = input_data.shape[0]\n",
    "        if i == 0:\n",
    "            output_data = harp_data[[\"Short\", \"Long\"]].to_numpy()\n",
    "            output[:n_timesteps, :] = output_data\n",
    "\n",
    "        input_[:n_timesteps, i, :] = input_data\n",
    "\n",
    "    return input_, output\n",
    "\n",
    "\n",
    "def get_data(size=1000):\n",
    "    X, y = [], []\n",
    "    for _ in tqdm(range(size)):\n",
    "        X_, y_ = create_train_data_tuple()\n",
    "        X.append(X_)\n",
    "        y.append(y_)\n",
    "    return X, y\n",
    "\n",
    "X, y = get_data(1000)\n",
    "X_val, y_val = get_data(100)\n",
    "\n",
    "print(np.any(np.isnan(X)))\n",
    "print(np.any(np.isnan(y)))\n",
    "print(np.any(np.isnan(X_val)))\n",
    "print(np.any(np.isnan(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0: mean_loss = 0.05319864000281086\n",
      "EPOCH 0: val_loss = 0.016247836872935295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1: mean_loss = 0.0008050289155653445\n",
      "EPOCH 1: val_loss = 0.009096811525523663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2: mean_loss = 0.0005437742564026848\n",
      "EPOCH 2: val_loss = 0.006016748026013374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3: mean_loss = 0.0005651527261034062\n",
      "EPOCH 3: val_loss = 0.0025222860276699066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4: mean_loss = 0.0003520178583858069\n",
      "EPOCH 4: val_loss = 0.0035190414637327194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5: mean_loss = 0.00015316514294681836\n",
      "EPOCH 5: val_loss = 0.0024403678253293037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6: mean_loss = 0.00018476169545465383\n",
      "EPOCH 6: val_loss = 0.0022367103956639767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 7: mean_loss = 0.00021666039833689865\n",
      "EPOCH 7: val_loss = 0.001420822343789041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 8: mean_loss = 8.403554178585182e-05\n",
      "EPOCH 8: val_loss = 0.0015561613254249096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 9: mean_loss = 2.5262686369842414e-05\n",
      "EPOCH 9: val_loss = 0.0010481922654435039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    N = len(X) // BATCH_SIZE\n",
    "    for batch in tqdm(range(N)):\n",
    "        X_batch, y_batch = X[epoch*BATCH_SIZE:(epoch+1)*BATCH_SIZE], y[epoch*BATCH_SIZE:(epoch+1)*BATCH_SIZE]\n",
    "        X_batch, y_batch = np.array(X_batch), np.array(y_batch)\n",
    "        \n",
    "        assert not np.any(np.isnan(X_batch)), \"X_batch should not include nan\"\n",
    "        assert not np.any(np.isnan(y_batch)), \"y_batch should not include nan\"\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred, _ = t((X_batch, y_batch), training=False)\n",
    "        \n",
    "            assert not np.any(np.isnan(y_pred)), \"y_pred should not include nan\"\n",
    "        \n",
    "            loss_value = loss(y_batch, y_pred)\n",
    "        \n",
    "        gradients = tape.gradient(loss_value, t.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, t.trainable_variables))\n",
    "        \n",
    "        total_loss += loss_value.numpy()\n",
    "\n",
    "    print(f\"EPOCH {epoch}: mean_loss = {total_loss / N}\")\n",
    "    \n",
    "    y_pred_val, _ = t((np.array(X_val), np.array(y_val)))\n",
    "    val_loss = loss(y_val, y_pred_val).numpy()\n",
    "    \n",
    "    print(f\"EPOCH {epoch}: val_loss = {val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "MODELNAME = \"8h-1\"\n",
    "\n",
    "metadata[\"n_timesteps\"]  = N_TIMESTEPS\n",
    "metadata[\"max_n_harps\"]  = MAX_N_HARPS\n",
    "metadata[\"n_features\"] = N_FEATURES\n",
    "metadata[\"n_out\"]  = N_OUT\n",
    "metadata[\"num_layers\"] = NUM_LAYERS\n",
    "metadata[\"d_model\"] = D_MODEL\n",
    "metadata[\"num_heads\"] = NUM_HEADS\n",
    "metadata[\"dff\"] = DFF\n",
    "metadata[\"input_dim\"] = INPUT_DIM\n",
    "metadata[\"output_dim\"] = OUTPUT_DIM\n",
    "metadata[\"rate\"] = RATE\n",
    "\n",
    "\n",
    "\n",
    "t.save_weights(\"models/\"+MODELNAME)\n",
    "with open(\"meta/\"+MODELNAME+\".pkl\", \"wb\") as metafile:\n",
    "    metafile.write(pickle.dumps(metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras import models\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformer import Transformer\n",
    "\n",
    "\n",
    "class Avocato():\n",
    "    def __init__(self, modelname):\n",
    "        self.metadata = pickle.load(\n",
    "            open(\"/mnt/hackathon2021/modelcache/meta/\" + modelname + \".pkl\",\n",
    "                 \"rb\"))\n",
    "        self.model = Transformer(\n",
    "            num_layers=self.metadata[\"num_layers\"],\n",
    "            d_model=self.metadata[\"d_model\"],\n",
    "            num_heads=self.metadata[\"num_heads\"],\n",
    "            dff=self.metadata[\"dff\"],\n",
    "            input_dimensions=self.metadata[\"input_dim\"],\n",
    "            target_dimensions=self.metadata[\"output_dim\"],\n",
    "            rate=self.metadata[\"rate\"],\n",
    "        )\n",
    "        self.model.compile()\n",
    "        self.model.load_weights(\"/mnt/hackathon2021/modelcache/models/\" +\n",
    "                                modelname)\n",
    "\n",
    "    def __call__(self, net_in):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        -----\n",
    "            - net_in: pd dataframe consisting of n_timesteps of data for HARPS (timestamp, harp, ...parameters)\n",
    "        \"\"\"\n",
    "\n",
    "        in_data = np.zeros(\n",
    "            (1, self.metadata[\"n_timesteps\"], self.metadata[\"max_n_harps\"],\n",
    "             self.metadata[\"n_features\"]))\n",
    "        unique_timesteps = net_in[\"timestamp\"].unique()\n",
    "        for t_id, timestep in enumerate(unique_timesteps):\n",
    "            if t_id >= self.metadata[\"n_timesteps\"]:\n",
    "                continue\n",
    "            unique_harps = net_in[net_in[\"timestamp\"] ==\n",
    "                                  timestep][\"harp\"].unique()\n",
    "            for h_id, harp in enumerate(unique_harps):\n",
    "                if h_id >= self.metadata[\"max_n_harps\"]:\n",
    "                    continue\n",
    "                in_data[0, t_id, h_id] = net_in[\n",
    "                    (net_in[\"timestamp\"] == timestep) &\n",
    "                    (net_in[\"harp\"] == harp\n",
    "                     )].loc[:,\n",
    "                            net_in.columns != \"timestamp\"].to_numpy().reshape(\n",
    "                                self.metadata[\"n_features\"])\n",
    "                in_data[0, t_id, h_id] -= self.metadata[\"sharp_mean\"]\n",
    "                in_data[0, t_id, h_id] /= self.metadata[\"sharp_std\"]\n",
    "\n",
    "        output = np.zeros((\n",
    "            1,\n",
    "            self.metadata[\"n_timesteps\"],\n",
    "            self.metadata[\"n_out\"],\n",
    "        ))\n",
    "\n",
    "        for i in tf.range(self.metadata[\"n_timesteps\"]):\n",
    "            output, _ = self.model([in_data, output],\n",
    "                                              training=False)\n",
    "\n",
    "        return output * self.metadata[\"xray_std\"] + self.metadata[\"xray_mean\"], output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = \"8h-1\"\n",
    "pred = Avocato(MODELNAME)\n",
    "random_time = datetime.fromtimestamp(int(data.sample(1)[\"timestamp\"]))\n",
    "start, end = (random_time -\n",
    "                timedelta(hours=1)).timestamp(), random_time.timestamp()\n",
    "net_in = data[(data[\"timestamp\"] > start) & (data[\"timestamp\"] <= end)]\n",
    "net_in = net_in[sharp_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 5, 2), dtype=float32, numpy=\n",
       " array([[[2.9338644e-08, 8.2975248e-08],\n",
       "         [2.9338644e-08, 8.2975248e-08],\n",
       "         [2.9338640e-08, 8.2975255e-08],\n",
       "         [2.9338642e-08, 8.2975248e-08],\n",
       "         [2.9338645e-08, 8.2975248e-08]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5, 2), dtype=float32, numpy=\n",
       " array([[[0.39534798, 0.02663079],\n",
       "         [0.39534798, 0.02663079],\n",
       "         [0.3953478 , 0.02663084],\n",
       "         [0.39534786, 0.02663079],\n",
       "         [0.3953481 , 0.02663079]]], dtype=float32)>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(net_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net_in' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_249611/22417529.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'net_in' is not defined"
     ]
    }
   ],
   "source": [
    "net_in.columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cparms_sg000</th>\n",
       "      <th>magnetogram_bzero</th>\n",
       "      <th>magnetogram_bscale</th>\n",
       "      <th>cparms_sg001</th>\n",
       "      <th>bitmap_bzero</th>\n",
       "      <th>bitmap_bscale</th>\n",
       "      <th>cparms_sg002</th>\n",
       "      <th>Dopplergram_bzero</th>\n",
       "      <th>Dopplergram_bscale</th>\n",
       "      <th>...</th>\n",
       "      <th>ERRVF</th>\n",
       "      <th>ERRALP</th>\n",
       "      <th>ERRMIH</th>\n",
       "      <th>ERRMSHA</th>\n",
       "      <th>ERRUSI</th>\n",
       "      <th>DOFFSET</th>\n",
       "      <th>ERRTPOT</th>\n",
       "      <th>ERRJHT</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>harp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.171258e+17</td>\n",
       "      <td>0.039924</td>\n",
       "      <td>0.008627</td>\n",
       "      <td>0.556</td>\n",
       "      <td>3.324596e+10</td>\n",
       "      <td>50</td>\n",
       "      <td>2.392323e+19</td>\n",
       "      <td>1.272943e+11</td>\n",
       "      <td>1.546301e+09</td>\n",
       "      <td>7331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.171377e+17</td>\n",
       "      <td>0.038964</td>\n",
       "      <td>0.009232</td>\n",
       "      <td>0.265</td>\n",
       "      <td>3.339996e+10</td>\n",
       "      <td>50</td>\n",
       "      <td>2.413159e+19</td>\n",
       "      <td>1.278868e+11</td>\n",
       "      <td>1.546302e+09</td>\n",
       "      <td>7331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.182555e+17</td>\n",
       "      <td>0.037166</td>\n",
       "      <td>0.009483</td>\n",
       "      <td>0.109</td>\n",
       "      <td>3.182180e+10</td>\n",
       "      <td>50</td>\n",
       "      <td>2.383180e+19</td>\n",
       "      <td>1.218468e+11</td>\n",
       "      <td>1.546302e+09</td>\n",
       "      <td>7331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.830374e+17</td>\n",
       "      <td>0.038684</td>\n",
       "      <td>0.008702</td>\n",
       "      <td>0.171</td>\n",
       "      <td>3.616783e+10</td>\n",
       "      <td>50</td>\n",
       "      <td>2.454871e+19</td>\n",
       "      <td>1.384912e+11</td>\n",
       "      <td>1.546303e+09</td>\n",
       "      <td>7331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.053047e+17</td>\n",
       "      <td>0.041713</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>0.154</td>\n",
       "      <td>3.308871e+10</td>\n",
       "      <td>50</td>\n",
       "      <td>2.928638e+19</td>\n",
       "      <td>1.267038e+11</td>\n",
       "      <td>1.546304e+09</td>\n",
       "      <td>7331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16929</th>\n",
       "      <td>934</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.029509e+18</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.053</td>\n",
       "      <td>2.715716e+10</td>\n",
       "      <td>50</td>\n",
       "      <td>1.974989e+19</td>\n",
       "      <td>1.040528e+11</td>\n",
       "      <td>1.577782e+09</td>\n",
       "      <td>7399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16930</th>\n",
       "      <td>935</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009294e+18</td>\n",
       "      <td>0.008267</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.134</td>\n",
       "      <td>2.650128e+10</td>\n",
       "      <td>50</td>\n",
       "      <td>1.929523e+19</td>\n",
       "      <td>1.015391e+11</td>\n",
       "      <td>1.577783e+09</td>\n",
       "      <td>7399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16931</th>\n",
       "      <td>936</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.027038e+18</td>\n",
       "      <td>0.008327</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.183</td>\n",
       "      <td>2.663215e+10</td>\n",
       "      <td>50</td>\n",
       "      <td>1.873955e+19</td>\n",
       "      <td>1.020396e+11</td>\n",
       "      <td>1.577784e+09</td>\n",
       "      <td>7399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16932</th>\n",
       "      <td>937</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.158489e+18</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.314</td>\n",
       "      <td>2.972004e+10</td>\n",
       "      <td>50</td>\n",
       "      <td>2.213047e+19</td>\n",
       "      <td>1.138669e+11</td>\n",
       "      <td>1.577786e+09</td>\n",
       "      <td>7399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16933</th>\n",
       "      <td>938</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>compress Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.116696e+18</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.171</td>\n",
       "      <td>2.849798e+10</td>\n",
       "      <td>50</td>\n",
       "      <td>2.168629e+19</td>\n",
       "      <td>1.091834e+11</td>\n",
       "      <td>1.577786e+09</td>\n",
       "      <td>7399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16934 rows × 218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   cparms_sg000  magnetogram_bzero  magnetogram_bscale  \\\n",
       "0               0  compress Rice                  0                 0.1   \n",
       "1               1  compress Rice                  0                 0.1   \n",
       "2               2  compress Rice                  0                 0.1   \n",
       "3               3  compress Rice                  0                 0.1   \n",
       "4               4  compress Rice                  0                 0.1   \n",
       "...           ...            ...                ...                 ...   \n",
       "16929         934  compress Rice                  0                 0.1   \n",
       "16930         935  compress Rice                  0                 0.1   \n",
       "16931         936  compress Rice                  0                 0.1   \n",
       "16932         937  compress Rice                  0                 0.1   \n",
       "16933         938  compress Rice                  0                 0.1   \n",
       "\n",
       "      cparms_sg001  bitmap_bzero  bitmap_bscale   cparms_sg002  \\\n",
       "0          MISSING             0              1  compress Rice   \n",
       "1          MISSING             0              1  compress Rice   \n",
       "2          MISSING             0              1  compress Rice   \n",
       "3          MISSING             0              1  compress Rice   \n",
       "4          MISSING             0              1  compress Rice   \n",
       "...            ...           ...            ...            ...   \n",
       "16929      MISSING             0              1  compress Rice   \n",
       "16930      MISSING             0              1  compress Rice   \n",
       "16931      MISSING             0              1  compress Rice   \n",
       "16932      MISSING             0              1  compress Rice   \n",
       "16933      MISSING             0              1  compress Rice   \n",
       "\n",
       "       Dopplergram_bzero  Dopplergram_bscale  ...         ERRVF    ERRALP  \\\n",
       "0                      0                 0.5  ...  5.171258e+17  0.039924   \n",
       "1                      0                 0.5  ...  5.171377e+17  0.038964   \n",
       "2                      0                 0.5  ...  5.182555e+17  0.037166   \n",
       "3                      0                 0.5  ...  5.830374e+17  0.038684   \n",
       "4                      0                 0.5  ...  5.053047e+17  0.041713   \n",
       "...                  ...                 ...  ...           ...       ...   \n",
       "16929                  0                 0.5  ...  1.029509e+18  0.007906   \n",
       "16930                  0                 0.5  ...  1.009294e+18  0.008267   \n",
       "16931                  0                 0.5  ...  1.027038e+18  0.008327   \n",
       "16932                  0                 0.5  ...  1.158489e+18  0.008915   \n",
       "16933                  0                 0.5  ...  1.116696e+18  0.008792   \n",
       "\n",
       "         ERRMIH ERRMSHA        ERRUSI  DOFFSET       ERRTPOT        ERRJHT  \\\n",
       "0      0.008627   0.556  3.324596e+10       50  2.392323e+19  1.272943e+11   \n",
       "1      0.009232   0.265  3.339996e+10       50  2.413159e+19  1.278868e+11   \n",
       "2      0.009483   0.109  3.182180e+10       50  2.383180e+19  1.218468e+11   \n",
       "3      0.008702   0.171  3.616783e+10       50  2.454871e+19  1.384912e+11   \n",
       "4      0.009019   0.154  3.308871e+10       50  2.928638e+19  1.267038e+11   \n",
       "...         ...     ...           ...      ...           ...           ...   \n",
       "16929  0.001896   0.053  2.715716e+10       50  1.974989e+19  1.040528e+11   \n",
       "16930  0.002059   0.134  2.650128e+10       50  1.929523e+19  1.015391e+11   \n",
       "16931  0.002050   0.183  2.663215e+10       50  1.873955e+19  1.020396e+11   \n",
       "16932  0.001988   0.314  2.972004e+10       50  2.213047e+19  1.138669e+11   \n",
       "16933  0.001940   0.171  2.849798e+10       50  2.168629e+19  1.091834e+11   \n",
       "\n",
       "          timestamp  harp  \n",
       "0      1.546301e+09  7331  \n",
       "1      1.546302e+09  7331  \n",
       "2      1.546302e+09  7331  \n",
       "3      1.546303e+09  7331  \n",
       "4      1.546304e+09  7331  \n",
       "...             ...   ...  \n",
       "16929  1.577782e+09  7399  \n",
       "16930  1.577783e+09  7399  \n",
       "16931  1.577784e+09  7399  \n",
       "16932  1.577786e+09  7399  \n",
       "16933  1.577786e+09  7399  \n",
       "\n",
       "[16934 rows x 218 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(f'/mnt/hackathon2021/Weltraumwetterlage/own_data/sharp/2019.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "abbc665463d35b62cca70309c790e7d0ad7bb1e4d5ea5962f40350218dd6908d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
